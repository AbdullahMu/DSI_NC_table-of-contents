{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss functions\n",
    "\n",
    "Regressions model the relationship between predictors and dependent variables. But the relationship they are measuring and the process of \"fitting\" model is centered around the idea of loss functions.\n",
    "\n",
    "The loss function is what is being optimized by the process of regression. Think of the term \"loss function\" sort of like the greater the value, the more information about your target variable that is \"lost\" by your model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Packages and data\n",
    "\n",
    "Load, for now, the following data and packages.\n",
    "\n",
    "The data is a subset of the football combine statistics you saw in a previous lecture. The concept of \"train\" and \"test\" datasets is going to repeatedly come up throughout the course. Imagine training data as the data you have now, and the test data as unobserved data which you validate the performance of your model on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/football_combine/combine_train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Back to a simple linear model\n",
    "\n",
    "Say we have a simple linear regression with a target variable $y$ and predictor variable $x$.\n",
    "\n",
    "Linear regression solves for the \"expected value\" $E[y]$ (mean) of $y$ \n",
    "\n",
    "The $E[x]$ of y modeled with a coefficient $\\beta_1$ times $x$ plus an intercept $\\beta_0$:\n",
    "\n",
    "### $$y = \\beta_0+\\beta_1x_1$$\n",
    "\n",
    "---\n",
    "\n",
    "### 1. Set up variables and build a regression predicting target from predictor\n",
    "\n",
    "Again, your regression should just be a single target and single predictor for now.\n",
    "\n",
    "You can choose any target and predictor that interests you, and you can subset the data if you like as well (subsetting on position, for example, is likely to improve a regression.)\n",
    "\n",
    "You may use statsmodels or scikit-learn to build the regression:\n",
    "\n",
    "    import statsmodels.api as sm\n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    \n",
    "Note that sklearn's regression expects your x variable to be a 2D matrix with rows, columns. See here:\n",
    "\n",
    "http://stackoverflow.com/questions/30813044/sklearn-found-arrays-with-inconsistent-numbers-of-samples-when-calling-linearre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "targets = pd.DataFrame(combine, columns=['PickTotal'])\n",
    "df = pd.DataFrame(combine, columns=['Year','Name','Position','Bench'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370555.501167\n"
     ]
    }
   ],
   "source": [
    "x = targets['PickTotal']\n",
    "y = df['Bench']\n",
    "\n",
    "model = sm.OLS(y,x).fit()\n",
    "predictions = model.predict(x)\n",
    "\n",
    "print model.mse_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Least squares loss\n",
    "\n",
    "As you may recall from yesterday, the most common loss function in linear regression is the **least squares loss** It is called least squared loss because it minimizes the sum of the squared errors/residuals.\n",
    "\n",
    "### $$\\sum_{i}{\\left(\\hat{y}_i - y_i \\right)^2}$$\n",
    "\n",
    "This is called a **loss function**. The \"loss\" is considered the increasing sum of squared errors, which indicate a bad fit between predictors and outcome. We minimize the loss by finding the smallest sum.\n",
    "\n",
    "---\n",
    "\n",
    "### 2. Calculate the mean squared error for your regression and the baseline model\n",
    "\n",
    "**Mean squared error** is just the mean of your squared errors. It is typically used as a metric in place of the sum of errors.\n",
    "\n",
    "Either calculate the mean squared error for your regression and baseline model by hand, or use statsmodels/sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 3. Plot the predictor vs. target and the predicted values vs. true values\n",
    "\n",
    "Add the regression line and the baseline model line for the predictor vs. target chart.\n",
    "\n",
    "Add a line that would pass through the origin with slope 1 on the values vs. true values chart.\n",
    "\n",
    "What do the lines represent in each chart?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## $R^2$ of the regression\n",
    "\n",
    "Recall that the $R^2$ metric calculates the variance explained by your model over the baseline model.\n",
    "\n",
    "The formula, to refresh your memory, is:\n",
    "\n",
    "### $$ R^2 = 1 - \\frac{var(residuals)}{var(y)} $$\n",
    "\n",
    "### 4. Calculate the $R^2$ either by hand or using sklearn or statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 5. Remove outliers and build a non-outlier regression\n",
    "\n",
    "Set a criteria for outliers that removes any value deviating more than 1.5 standard deviations from the mean. (Extremely strict).\n",
    "\n",
    "Build a new regression with the non-outlier values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 6. Plot the regression with the outliers and without the outliers\n",
    "\n",
    "Use the full data for both (not the data with outliers removed).\n",
    "\n",
    "How do the regression lines change (if at all). Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### 7. Calculate the $R^2$ of your outlier-removed model and compare it to the original model\n",
    "\n",
    "Which performs better? Why do you think that is?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Examining residuals\n",
    "\n",
    "Looking at the residuals (errors) of your model is a good practice. Normally distributed residuals indicate that the assumptions of linear regression are probably being met, which in turn means that your regression is modeling the linear relationship appropriately.\n",
    "\n",
    "### 8. Plot a histogram of the residuals from the original and no-outlier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Validating the model against a test set\n",
    "\n",
    "Load in the test set file for the combine data. Pull out the corresponding target and predictor variables for the test set.\n",
    "\n",
    "It is best practice after you build a model to, if possible, validate it against held out data. If it performs as well or nearly as well, you can be more sure that the model you've created is in fact making a correct inference about the linear relationship between variables for the overall population.\n",
    "\n",
    "### 9. Get the $R^2$ value for your original model predicting values from the test data\n",
    "\n",
    "Compare this to the $R^2$ on your training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combine_test = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/football_combine/combine_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Calculate the mse for the test data and baseline model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. Plot the regression applied to test data against the test data baseline model\n",
    "\n",
    "Look visually how it performs versus just guessing the mean of the target in the test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
