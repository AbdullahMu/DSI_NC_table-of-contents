{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis codealong using spacy and movie reviews\n",
    "\n",
    "Sentiment analysis is one of the more popular topics in NLP. It is concerned with finding some kind of valence to written text. This could be positivity, negativity, subjectivity and many others. In this lesson we will just be looking at those three. \n",
    "\n",
    "First we will load in a dataset of pre-coded sentiment scores for positivity and negativity on words. These words are also divided up by their part of speech in the sentence.\n",
    "\n",
    "Then we will load snippets of rottentomatoes reviews and explore the sentiment of the writing.\n",
    "\n",
    "---\n",
    "\n",
    "### Load packages and sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/sentiment_words/sentiment_words_simple.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10978</th>\n",
       "      <td>adj</td>\n",
       "      <td>magnificent</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       pos         word  pos_score  neg_score\n",
       "10978  adj  magnificent        0.5       0.25"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen[sen.word == 'magnificent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos</th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3686</th>\n",
       "      <td>adj</td>\n",
       "      <td>cheapjack</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115694</th>\n",
       "      <td>noun</td>\n",
       "      <td>scut_work</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8534</th>\n",
       "      <td>adj</td>\n",
       "      <td>henpecked</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117755</th>\n",
       "      <td>noun</td>\n",
       "      <td>shitwork</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10290</th>\n",
       "      <td>adj</td>\n",
       "      <td>lamentable</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32976</th>\n",
       "      <td>noun</td>\n",
       "      <td>blackguard</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25791</th>\n",
       "      <td>noun</td>\n",
       "      <td>angriness</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91963</th>\n",
       "      <td>noun</td>\n",
       "      <td>motormouth</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5782</th>\n",
       "      <td>adj</td>\n",
       "      <td>distressing</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.937500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19500</th>\n",
       "      <td>adj</td>\n",
       "      <td>unfortunate</td>\n",
       "      <td>0.037</td>\n",
       "      <td>0.921333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pos         word  pos_score  neg_score\n",
       "3686     adj    cheapjack      0.000   1.000000\n",
       "115694  noun    scut_work      0.000   1.000000\n",
       "8534     adj    henpecked      0.000   1.000000\n",
       "117755  noun     shitwork      0.000   1.000000\n",
       "10290    adj   lamentable      0.000   1.000000\n",
       "32976   noun   blackguard      0.000   1.000000\n",
       "25791   noun    angriness      0.000   1.000000\n",
       "91963   noun   motormouth      0.000   1.000000\n",
       "5782     adj  distressing      0.000   0.937500\n",
       "19500    adj  unfortunate      0.037   0.921333"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen.sort_values('neg_score', ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a sentiment dataset that does not take into account part of speech tags\n",
    "\n",
    "This will be what we use first, not knowing the part of speech a word is in. Later when we use spacy we will be able to determine the part of speech of each word and pair the scores accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>pos_score</th>\n",
       "      <th>neg_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'hood</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>'s_gravenhage</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>'tween</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'tween_decks</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.22</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            word  pos_score  neg_score\n",
       "0          'hood      0.000      0.375\n",
       "1  's_gravenhage      0.000      0.000\n",
       "2         'tween      0.000      0.000\n",
       "3   'tween_decks      0.000      0.000\n",
       "4            .22      0.125      0.000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_agg = sen[['word','pos_score','neg_score']].groupby('word').agg(np.mean).reset_index()\n",
    "sen_agg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create a dictionary version of the sentiment data for both the part of speech and aggregate\n",
    "\n",
    "The dictionary format of the data will be much easier to index into in our functions later. If we don't do this it's much harder to make those functions run quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sen_dict = {\n",
    "    'ADJ':{},\n",
    "    'NOUN':{},\n",
    "    'VERB':{},\n",
    "    'ADV':{}\n",
    "}\n",
    "\n",
    "for i, row in enumerate(sen.itertuples()):\n",
    "    #if (i % 10000) == 0:\n",
    "    #    print i\n",
    "    sen_dict[row[1].upper()][row[2]] = {'pos_score':row[3], 'neg_score':row[4]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_score': 0.75, 'pos_score': 0.25}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_dict['ADJ']['worst']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sen_agg_dict = {}\n",
    "for row in sen_agg.itertuples():\n",
    "    sen_agg_dict[row[1]] = {'pos_score':row[2], 'neg_score':row[3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'neg_score': 0.63541666666675001, 'pos_score': 0.125}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen_agg_dict['worst']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Load the rotten tomatoes dataset\n",
    "\n",
    "This dataset has:\n",
    "    \n",
    "    critic: critic's name\n",
    "    fresh: fresh vs. rotten rating\n",
    "    imdb: code for imdb\n",
    "    publication: where the review was published\n",
    "    quote: the review snippet\n",
    "    review_date: date of review\n",
    "    rtid: rottentomatoes id\n",
    "    title: name of movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt = pd.read_csv('/Users/kiefer/github-repos/DSI-SF-2/datasets/rottentomatoes_critics/rt_critics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Richard Corliss</td>\n",
       "      <td>fresh</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>TIME Magazine</td>\n",
       "      <td>The year's most inventive comedy.</td>\n",
       "      <td>2008-08-31</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            critic  fresh      imdb    publication  \\\n",
       "0      Derek Adams  fresh  114709.0       Time Out   \n",
       "1  Richard Corliss  fresh  114709.0  TIME Magazine   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1                  The year's most inventive comedy.  2008-08-31  9559.0   \n",
       "\n",
       "       title  \n",
       "0  Toy story  \n",
       "1  Toy story  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Restrict data to reviews with valid ratings and reviews over 10 words long\n",
    "\n",
    "Clean up the reviews, making a column with the case and punctuation removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['fresh', 'rotten', 'none'], dtype=object)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.fresh.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt = rt[rt.fresh.isin(['fresh','rotten'])]\n",
    "rt.fresh = rt.fresh.map(lambda x: 1 if x == 'fresh' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11215, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt['quote_len'] = rt.quote.map(lambda x: len(x.split()))\n",
    "rt = rt[rt.quote_len > 10]\n",
    "rt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So ingenious in concept, design and execution that you could watch it on a postage stamp-sized screen and still be engulfed by its charm.\n",
      "A winning animated feature that has something for everyone on the age spectrum.\n",
      "The film sports a provocative and appealing story that's every bit the equal of this technical achievement.\n",
      "An entertaining computer-generated, hyperrealist animation feature (1995) that's also in effect a toy catalog.\n"
     ]
    }
   ],
   "source": [
    "for q in rt.quote.values[0:4]:\n",
    "    print q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>24</td>\n",
       "      <td>so ingenious in concept design and execution t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>13</td>\n",
       "      <td>a winning animated feature that has something ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        critic  fresh      imdb publication  \\\n",
       "0  Derek Adams      1  114709.0    Time Out   \n",
       "2  David Ansen      1  114709.0    Newsweek   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "\n",
       "       title  quote_len                                                 qt  \n",
       "0  Toy story         24  so ingenious in concept design and execution t...  \n",
       "2  Toy story         13  a winning animated feature that has something ...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.ascii_lowercase\n",
    "\n",
    "rt['qt'] = rt.quote.map(lambda x: unicode(''.join([ch for ch in list(x.lower()) \n",
    "                                                    if ch in string.ascii_lowercase+\" -'\"])))\n",
    "\n",
    "rt.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Write a function to assign positive rating, negative, and objective based on words in review\n",
    "\n",
    "We'll use the dictionary we constructed above (without the part of speech tags). \n",
    "\n",
    "Objectivity is calculated: \n",
    "\n",
    "    1. - (positive_score + negative_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agg_scorer(x):\n",
    "    x = x.split()\n",
    "    pos_scores, neg_scores, obj_scores = [], [], []\n",
    "    for word in x:\n",
    "        try:\n",
    "            pos_scores.append(sen_agg_dict[word]['pos_score'])\n",
    "            neg_scores.append(sen_agg_dict[word]['neg_score'])\n",
    "            obj_scores.append((1. - (pos_scores[-1] + neg_scores[-1])))\n",
    "        except:\n",
    "            pos_scores.append(0.)\n",
    "            neg_scores.append(0.)\n",
    "            obj_scores.append(1.)\n",
    "    return [pos_scores, neg_scores, obj_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'children will enjoy a new take on the irresistible idea of toys coming to life adults will marvel at a witty script and utterly brilliant anthropomorphism'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev = rt.qt[7]\n",
    "rev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p, n, o = agg_scorer(rev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "children 0.0\n",
      "will 0.0\n",
      "enjoy 0.05\n",
      "a 0.0357142857143\n",
      "new 0.056818181818\n",
      "take 0.014880952381\n",
      "on 0.0\n",
      "the 0.0\n",
      "irresistible 0.375\n",
      "idea 0.075\n",
      "of 0.0\n",
      "toys 0.0\n",
      "coming 0.0\n",
      "to 0.0\n",
      "life 0.0\n",
      "adults 0.0\n",
      "will 0.0\n",
      "marvel 0.03125\n",
      "at 0.0\n",
      "a 0.0357142857143\n",
      "witty 0.0\n",
      "script 0.0\n",
      "and 0.0\n",
      "utterly 0.0\n",
      "brilliant 0.0625\n",
      "anthropomorphism 0.0\n"
     ]
    }
   ],
   "source": [
    "for word, n_ in zip(rev.split(), n):\n",
    "    print word, n_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Calculate the sum and average ratings for positive, negative, and objective for each review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "agg_scores = map(agg_scorer, rt.qt)\n",
    "\n",
    "rt['pos_avg'] = [np.mean(x[0]) for x in agg_scores]\n",
    "rt['neg_avg'] = [np.mean(x[1]) for x in agg_scores]\n",
    "rt['obj_avg'] = [np.mean(x[2]) for x in agg_scores]\n",
    "\n",
    "rt['pos_sum'] = [np.sum(x[0]) for x in agg_scores]\n",
    "rt['neg_sum'] = [np.sum(x[1]) for x in agg_scores]\n",
    "rt['obj_sum'] = [np.sum(x[2]) for x in agg_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "      <th>pos_avg</th>\n",
       "      <th>neg_avg</th>\n",
       "      <th>obj_avg</th>\n",
       "      <th>pos_sum</th>\n",
       "      <th>neg_sum</th>\n",
       "      <th>obj_sum</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>24</td>\n",
       "      <td>so ingenious in concept design and execution t...</td>\n",
       "      <td>0.045647</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>0.929647</td>\n",
       "      <td>1.095524</td>\n",
       "      <td>0.592949</td>\n",
       "      <td>22.311527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>13</td>\n",
       "      <td>a winning animated feature that has something ...</td>\n",
       "      <td>0.062271</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.915751</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>11.904762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>17</td>\n",
       "      <td>the film sports a provocative and appealing st...</td>\n",
       "      <td>0.057831</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>0.917897</td>\n",
       "      <td>0.983135</td>\n",
       "      <td>0.412608</td>\n",
       "      <td>15.604257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jonathan Rosenbaum</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Chicago Reader</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "      <td>2008-03-10</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>14</td>\n",
       "      <td>an entertaining computer-generated hyperrealis...</td>\n",
       "      <td>0.072688</td>\n",
       "      <td>0.042331</td>\n",
       "      <td>0.884982</td>\n",
       "      <td>0.944940</td>\n",
       "      <td>0.550298</td>\n",
       "      <td>11.504762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Michael Booth</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Denver Post</td>\n",
       "      <td>As Lion King did before it, Toy Story revived ...</td>\n",
       "      <td>2007-05-03</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>40</td>\n",
       "      <td>as lion king did before it toy story revived t...</td>\n",
       "      <td>0.028408</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.949657</td>\n",
       "      <td>1.136316</td>\n",
       "      <td>0.877397</td>\n",
       "      <td>37.986287</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               critic  fresh      imdb     publication  \\\n",
       "0         Derek Adams      1  114709.0        Time Out   \n",
       "2         David Ansen      1  114709.0        Newsweek   \n",
       "3       Leonard Klady      1  114709.0         Variety   \n",
       "4  Jonathan Rosenbaum      1  114709.0  Chicago Reader   \n",
       "5       Michael Booth      1  114709.0     Denver Post   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "2  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "3  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "4  An entertaining computer-generated, hyperreali...  2008-03-10  9559.0   \n",
       "5  As Lion King did before it, Toy Story revived ...  2007-05-03  9559.0   \n",
       "\n",
       "       title  quote_len                                                 qt  \\\n",
       "0  Toy story         24  so ingenious in concept design and execution t...   \n",
       "2  Toy story         13  a winning animated feature that has something ...   \n",
       "3  Toy story         17  the film sports a provocative and appealing st...   \n",
       "4  Toy story         14  an entertaining computer-generated hyperrealis...   \n",
       "5  Toy story         40  as lion king did before it toy story revived t...   \n",
       "\n",
       "    pos_avg   neg_avg   obj_avg   pos_sum   neg_sum    obj_sum  \n",
       "0  0.045647  0.024706  0.929647  1.095524  0.592949  22.311527  \n",
       "2  0.062271  0.021978  0.915751  0.809524  0.285714  11.904762  \n",
       "3  0.057831  0.024271  0.917897  0.983135  0.412608  15.604257  \n",
       "4  0.072688  0.042331  0.884982  0.944940  0.550298  11.504762  \n",
       "5  0.028408  0.021935  0.949657  1.136316  0.877397  37.986287  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Evaluate predictive ability using the sentiment scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.624431608768 0.615069103879\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "\n",
    "X = rt[['pos_avg','neg_avg','obj_avg','quote_len']]\n",
    "y = rt.fresh.values\n",
    "\n",
    "lr_scores = cross_val_score(LogisticRegression(), X, y, cv=10)\n",
    "print np.mean(lr_scores), np.mean(y)\n",
    "\n",
    "lr = LogisticRegression().fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pos_avg 9.09342432956\n",
      "neg_avg -7.52380496815\n",
      "obj_avg -0.776342845242\n",
      "quote_len 0.0115949884562\n"
     ]
    }
   ],
   "source": [
    "for predictor, coef in zip(X.columns, lr.coef_[0]):\n",
    "    print predictor, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pp = pd.DataFrame({\n",
    "        'prob_fresh':lr.predict_proba(X)[:,1],\n",
    "        'prob_rotten':lr.predict_proba(X)[:,0],\n",
    "        'quote':rt.quote.values\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_fresh</th>\n",
       "      <th>prob_rotten</th>\n",
       "      <th>quote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.640845</td>\n",
       "      <td>0.359155</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.653390</td>\n",
       "      <td>0.346610</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.650460</td>\n",
       "      <td>0.349540</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.648180</td>\n",
       "      <td>0.351820</td>\n",
       "      <td>An entertaining computer-generated, hyperreali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.648649</td>\n",
       "      <td>0.351351</td>\n",
       "      <td>As Lion King did before it, Toy Story revived ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prob_fresh  prob_rotten                                              quote\n",
       "0    0.640845     0.359155  So ingenious in concept, design and execution ...\n",
       "1    0.653390     0.346610  A winning animated feature that has something ...\n",
       "2    0.650460     0.349540  The film sports a provocative and appealing st...\n",
       "3    0.648180     0.351820  An entertaining computer-generated, hyperreali...\n",
       "4    0.648649     0.351351  As Lion King did before it, Toy Story revived ..."
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfortunately Mr. Fraser comes off as a forlorn, outsize Pee Wee Herman.\n",
      "===============================================\n",
      "\n",
      "Any room in that freezer for this inadequate, inauthentic, indigestible film?\n",
      "===============================================\n",
      "\n",
      "Its tone is never exactly comedic and its horrific touches are more disgusting than scary.\n",
      "===============================================\n",
      "\n",
      "It's a disturbing, hopeless, irredeemable series of images that will scar you if you wander into it unprepared.\n",
      "===============================================\n",
      "\n",
      "Unoriginal and insulting, 3 Strikes goes down without scoring a single chuckle.\n",
      "===============================================\n",
      "\n",
      "If inspiration is lacking, talent is not. Count Lynch down but never out.\n",
      "===============================================\n",
      "\n",
      "This is a terrible, terrible worthless movie that you shouldn't give any time to.\n",
      "===============================================\n",
      "\n",
      "The movie is marred by an overreliance on unfunny bathroom gags.\n",
      "===============================================\n",
      "\n",
      "This landmark movie's madcap humor and terrifying suspense remain undiminished by time.\n",
      "===============================================\n",
      "\n",
      "Uninspired actors intone a banal script, reduced by clumsy pacing to a minimum of suspense.\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp.sort_values('prob_rotten', ascending=False, inplace=True)\n",
    "for quote in pp.quote.values[0:10]:\n",
    "    print quote\n",
    "    print '===============================================\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prob_fresh</th>\n",
       "      <th>prob_rotten</th>\n",
       "      <th>quote</th>\n",
       "      <th>difference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4506</th>\n",
       "      <td>0.499924</td>\n",
       "      <td>0.500076</td>\n",
       "      <td>A shambolic, deafening, intelligence-insulting...</td>\n",
       "      <td>0.000152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10765</th>\n",
       "      <td>0.500093</td>\n",
       "      <td>0.499907</td>\n",
       "      <td>It's like watching the dreckiest of teen puppy...</td>\n",
       "      <td>0.000186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9491</th>\n",
       "      <td>0.500166</td>\n",
       "      <td>0.499834</td>\n",
       "      <td>This cockamamy action flick is excruciatingly ...</td>\n",
       "      <td>0.000333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3830</th>\n",
       "      <td>0.499817</td>\n",
       "      <td>0.500183</td>\n",
       "      <td>The film, for all its mayhem and fury, is too ...</td>\n",
       "      <td>0.000366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8824</th>\n",
       "      <td>0.499796</td>\n",
       "      <td>0.500204</td>\n",
       "      <td>The story is no more than a thread stitching s...</td>\n",
       "      <td>0.000408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       prob_fresh  prob_rotten  \\\n",
       "4506     0.499924     0.500076   \n",
       "10765    0.500093     0.499907   \n",
       "9491     0.500166     0.499834   \n",
       "3830     0.499817     0.500183   \n",
       "8824     0.499796     0.500204   \n",
       "\n",
       "                                                   quote  difference  \n",
       "4506   A shambolic, deafening, intelligence-insulting...    0.000152  \n",
       "10765  It's like watching the dreckiest of teen puppy...    0.000186  \n",
       "9491   This cockamamy action flick is excruciatingly ...    0.000333  \n",
       "3830   The film, for all its mayhem and fury, is too ...    0.000366  \n",
       "8824   The story is no more than a thread stitching s...    0.000408  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shambolic, deafening, intelligence-insulting mess, a crushing failure on almost all counts.\n",
      "===============================================\n",
      "\n",
      "It's like watching the dreckiest of teen puppy courtships trying to pass itself off as 'Annie Hall.\n",
      "===============================================\n",
      "\n",
      "This cockamamy action flick is excruciatingly formulaic -- brimming with spy movie cliches but devoid of the genre's fun, upper-class pretensions.\n",
      "===============================================\n",
      "\n",
      "The film, for all its mayhem and fury, is too distant to be truly disturbing; it treats everything with an impatient, born-too-late shrug.\n",
      "===============================================\n",
      "\n",
      "The story is no more than a thread stitching set pieces of increasing implausibility and ineptitude.\n",
      "===============================================\n",
      "\n",
      "This may work for you if you settle at the outset for a nostalgic, all-American mood piece.\n",
      "===============================================\n",
      "\n",
      "Notorious has a fine time along the way, with Woolard channeling the rapper's sweetness and wit as comfortably as his pathos.\n",
      "===============================================\n",
      "\n",
      "Never manages more than a glib, TV movie-of- the-week glance at their lives.\n",
      "===============================================\n",
      "\n",
      "An old hand at this sort of thing, Pakula goes through the motions, but not much more.\n",
      "===============================================\n",
      "\n",
      "Another soulless, by-the-numbers attempt to resurrect a genre that made money for the studios in the past.\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pp['difference'] = np.abs(pp.prob_fresh - pp.prob_rotten)\n",
    "pp.sort_values('difference', ascending=True, inplace=True)\n",
    "for quote in pp.quote.values[0:10]:\n",
    "    print quote\n",
    "    print '===============================================\\n'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hawthorne is by turn outrageous and pathetic and imperious and poignant and very funny.\n",
      "===============================================\n",
      "\n",
      "Rounders' script is pretty shabby going. Well, not shabby, really, just simplistic.\n",
      "===============================================\n",
      "\n",
      "Peter Berg's Very Bad Things isn't a bad movie, just a reprehensible one.\n",
      "===============================================\n",
      "\n",
      "Its tone is never exactly comedic and its horrific touches are more disgusting than scary.\n",
      "===============================================\n",
      "\n",
      "Bad taste of this order is rare but not yet dead.\n",
      "===============================================\n",
      "\n",
      "An anarchic slob movie, a celebration of all that is irreverent, reckless, foolhardy, undisciplined, and occasionally scatological. It's a lot of fun.\n",
      "===============================================\n",
      "\n",
      "A sprawling, rowdy, vital film laced with both outrageous absurdist dark humor and unspeakable pain, suffering and injustice.\n",
      "===============================================\n",
      "\n",
      "Regrettably, an overblown finale and redundant trick ending undercut the mild subversiveness of what's gone before.\n",
      "===============================================\n",
      "\n",
      "Not only is the picture woefully short on laughs, it's also coarse, overbearing and, in places, downright insulting.\n",
      "===============================================\n",
      "\n",
      "A generally dumb movie with a smart, appealing, gutsy leading lady.\n",
      "===============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for quote in rt.sort_values('neg_avg', ascending=False).quote.values[0:10]:\n",
    "    print quote\n",
    "    print '===============================================\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Import spacy\n",
    "\n",
    "The spacy package is the current gold standard for parsing text. We are going to use it to find the part of speech tags for the review words. \n",
    "\n",
    "Once we have parsed the tags with spacey, we can assign sentiment scores at a more granular level, using the correct part of speech version of the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "en_nlp = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "so ingenious in concept design and execution that you could watch it on a postage stamp-sized screen and still be engulfed by its charm"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt = en_nlp(rt.qt.values[0])\n",
    "txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADV\n",
      "ADJ\n",
      "ADP\n",
      "NOUN\n",
      "NOUN\n",
      "CONJ\n",
      "NOUN\n",
      "ADJ\n",
      "PRON\n",
      "VERB\n",
      "VERB\n",
      "PRON\n",
      "ADP\n",
      "DET\n",
      "NOUN\n",
      "NOUN\n",
      "PUNCT\n",
      "ADJ\n",
      "NOUN\n",
      "CONJ\n",
      "ADV\n",
      "VERB\n",
      "VERB\n",
      "ADP\n",
      "ADJ\n",
      "NOUN\n"
     ]
    }
   ],
   "source": [
    "for x in txt:\n",
    "    print x.pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "so"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token1 = txt[0]\n",
    "token1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'so '"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#str(token1) == 'so'\n",
    "token1.string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Parse the quotes using spacey's multithreaded parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "10000\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "parsed_quotes = []\n",
    "for i, parsed in enumerate(en_nlp.pipe(rt.qt.values, batch_size=50, n_threads=4)):\n",
    "    if (i % 1000) == 0:\n",
    "        print i\n",
    "    parsed_quotes.append(parsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADJ','ADP','ADV','CONJ','DET','INTJ','NOUN','NUM','PART','PRON','PROPN','PUNCT','SPACE','SYM','VERB','X\n"
     ]
    }
   ],
   "source": [
    "unique_pos = []\n",
    "for parsed in parsed_quotes:\n",
    "    unique_pos.extend([t.pos_ for t in parsed])\n",
    "unique_pos = np.unique(unique_pos)\n",
    "print \"','\".join(unique_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "useful_grammar = ['ADJ','ADP','ADV','CONJ','DET','INTJ','NOUN','PART','PRON','PROPN','VERB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for pos in useful_grammar:\n",
    "    rt[pos+'_prop'] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "7500\n",
      "8000\n",
      "8500\n",
      "9000\n",
      "9500\n",
      "10000\n",
      "10500\n",
      "11000\n"
     ]
    }
   ],
   "source": [
    "rt = rt.reset_index(drop=True)\n",
    "for i, parsed in enumerate(parsed_quotes):\n",
    "    if (i % 500) == 0:\n",
    "        print i\n",
    "    parsed_len = len(parsed)\n",
    "    for pos in useful_grammar:\n",
    "        prop = len([x for x in parsed if x.pos_ == pos]) / float(parsed_len)\n",
    "        rt.ix[i, pos+'_prop'] = prop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>critic</th>\n",
       "      <th>fresh</th>\n",
       "      <th>imdb</th>\n",
       "      <th>publication</th>\n",
       "      <th>quote</th>\n",
       "      <th>review_date</th>\n",
       "      <th>rtid</th>\n",
       "      <th>title</th>\n",
       "      <th>quote_len</th>\n",
       "      <th>qt</th>\n",
       "      <th>...</th>\n",
       "      <th>ADP_prop</th>\n",
       "      <th>ADV_prop</th>\n",
       "      <th>CONJ_prop</th>\n",
       "      <th>DET_prop</th>\n",
       "      <th>INTJ_prop</th>\n",
       "      <th>NOUN_prop</th>\n",
       "      <th>PART_prop</th>\n",
       "      <th>PRON_prop</th>\n",
       "      <th>PROPN_prop</th>\n",
       "      <th>VERB_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Derek Adams</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Time Out</td>\n",
       "      <td>So ingenious in concept, design and execution ...</td>\n",
       "      <td>2009-10-04</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>24</td>\n",
       "      <td>so ingenious in concept design and execution t...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>David Ansen</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Newsweek</td>\n",
       "      <td>A winning animated feature that has something ...</td>\n",
       "      <td>2008-08-18</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>13</td>\n",
       "      <td>a winning animated feature that has something ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Leonard Klady</td>\n",
       "      <td>1</td>\n",
       "      <td>114709.0</td>\n",
       "      <td>Variety</td>\n",
       "      <td>The film sports a provocative and appealing st...</td>\n",
       "      <td>2008-06-09</td>\n",
       "      <td>9559.0</td>\n",
       "      <td>Toy story</td>\n",
       "      <td>17</td>\n",
       "      <td>the film sports a provocative and appealing st...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.055556</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows  27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          critic  fresh      imdb publication  \\\n",
       "0    Derek Adams      1  114709.0    Time Out   \n",
       "1    David Ansen      1  114709.0    Newsweek   \n",
       "2  Leonard Klady      1  114709.0     Variety   \n",
       "\n",
       "                                               quote review_date    rtid  \\\n",
       "0  So ingenious in concept, design and execution ...  2009-10-04  9559.0   \n",
       "1  A winning animated feature that has something ...  2008-08-18  9559.0   \n",
       "2  The film sports a provocative and appealing st...  2008-06-09  9559.0   \n",
       "\n",
       "       title  quote_len                                                 qt  \\\n",
       "0  Toy story         24  so ingenious in concept design and execution t...   \n",
       "1  Toy story         13  a winning animated feature that has something ...   \n",
       "2  Toy story         17  the film sports a provocative and appealing st...   \n",
       "\n",
       "     ...      ADP_prop  ADV_prop  CONJ_prop  DET_prop  INTJ_prop  NOUN_prop  \\\n",
       "0    ...      0.115385  0.076923   0.076923  0.038462        0.0   0.269231   \n",
       "1    ...      0.153846  0.000000   0.000000  0.153846        0.0   0.384615   \n",
       "2    ...      0.055556  0.000000   0.055556  0.277778        0.0   0.277778   \n",
       "\n",
       "   PART_prop  PRON_prop  PROPN_prop  VERB_prop  \n",
       "0        0.0   0.076923         0.0   0.153846  \n",
       "1        0.0   0.000000         0.0   0.153846  \n",
       "2        0.0   0.000000         0.0   0.055556  \n",
       "\n",
       "[3 rows x 27 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Create columns for part of speech proportions\n",
    "\n",
    "For each of the part of speech tags, create a column in the dataset that records the proportion of words in the quote that have that part of speech tag. We can try using these as predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Evaluate a model with the new part of speech predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Print out the most likely fresh and most likely rotten reviews\n",
    "\n",
    "Using the predicted probabilities from our model, we can see which reviews are most likely to be fresh or rotten. We can easily validate that our model is doing something that makes sense by looking at these (one of the benefits of doing NLP work!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Assign sentiment scores using the correct part of speech tag\n",
    "\n",
    "We need to write another function that will take into account the part of speech tags using the parsed quotes we created earlier and the original sentiment data dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scorer(parsed):\n",
    "    pos_scores, neg_scores, obj_scores = [], [], []\n",
    "    for token in [t for t in parsed if t.pos_ in ['NOUN','VERB','ADV','ADJ']]:\n",
    "        try:\n",
    "            pos_scores.append(sen_dict[token.pos_][str(token)]['pos_score'])\n",
    "            neg_scores.append(sen_dict[token.pos_][str(token)]['neg_score'])\n",
    "            obj_scores.append(1. - (pos_scores[-1] + neg_scores[-1]))\n",
    "        except:\n",
    "            pos_scores.append(0.)\n",
    "            neg_scores.append(0.)\n",
    "            obj_scores.append(1.)\n",
    "    return [pos_scores, neg_scores, obj_scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = map(scorer, parsed_quotes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rt['pos_part_avg'] = [np.mean(x[0]) for x in scores]\n",
    "rt['neg_part_avg'] = [np.mean(x[1]) for x in scores]\n",
    "rt['obj_part_avg'] = [np.mean(x[2]) for x in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_avg</th>\n",
       "      <th>neg_avg</th>\n",
       "      <th>obj_avg</th>\n",
       "      <th>pos_part_avg</th>\n",
       "      <th>neg_part_avg</th>\n",
       "      <th>obj_part_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045647</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>0.929647</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.905260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.062271</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.915751</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057831</td>\n",
       "      <td>0.024271</td>\n",
       "      <td>0.917897</td>\n",
       "      <td>0.085227</td>\n",
       "      <td>0.030475</td>\n",
       "      <td>0.884298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.072688</td>\n",
       "      <td>0.042331</td>\n",
       "      <td>0.884982</td>\n",
       "      <td>0.071970</td>\n",
       "      <td>0.036742</td>\n",
       "      <td>0.891288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.028408</td>\n",
       "      <td>0.021935</td>\n",
       "      <td>0.949657</td>\n",
       "      <td>0.037870</td>\n",
       "      <td>0.013122</td>\n",
       "      <td>0.949009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.119091</td>\n",
       "      <td>0.045225</td>\n",
       "      <td>0.835684</td>\n",
       "      <td>0.101595</td>\n",
       "      <td>0.032503</td>\n",
       "      <td>0.865902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.112158</td>\n",
       "      <td>0.028341</td>\n",
       "      <td>0.859501</td>\n",
       "      <td>0.140578</td>\n",
       "      <td>0.042689</td>\n",
       "      <td>0.816733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.055437</td>\n",
       "      <td>0.019369</td>\n",
       "      <td>0.925193</td>\n",
       "      <td>0.067751</td>\n",
       "      <td>0.036273</td>\n",
       "      <td>0.895975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.025202</td>\n",
       "      <td>0.012446</td>\n",
       "      <td>0.962352</td>\n",
       "      <td>0.082465</td>\n",
       "      <td>0.038194</td>\n",
       "      <td>0.879340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.097777</td>\n",
       "      <td>0.011065</td>\n",
       "      <td>0.891158</td>\n",
       "      <td>0.174148</td>\n",
       "      <td>0.018466</td>\n",
       "      <td>0.807386</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    pos_avg   neg_avg   obj_avg  pos_part_avg  neg_part_avg  obj_part_avg\n",
       "0  0.045647  0.024706  0.929647      0.069186      0.025553      0.905260\n",
       "1  0.062271  0.021978  0.915751      0.020833      0.000000      0.979167\n",
       "2  0.057831  0.024271  0.917897      0.085227      0.030475      0.884298\n",
       "3  0.072688  0.042331  0.884982      0.071970      0.036742      0.891288\n",
       "4  0.028408  0.021935  0.949657      0.037870      0.013122      0.949009\n",
       "5  0.119091  0.045225  0.835684      0.101595      0.032503      0.865902\n",
       "6  0.112158  0.028341  0.859501      0.140578      0.042689      0.816733\n",
       "7  0.055437  0.019369  0.925193      0.067751      0.036273      0.895975\n",
       "8  0.025202  0.012446  0.962352      0.082465      0.038194      0.879340\n",
       "9  0.097777  0.011065  0.891158      0.174148      0.018466      0.807386"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rt[[col for col in rt.columns if col.endswith('_avg')]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Evaluate the new predictors with different models.\n",
    "\n",
    "Does regularization help? Decision trees?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = rt[['quote_len'] + [c for c in rt.columns if c.endswith('_avg')] + [c for c in rt.columns if c.endswith('_prop')]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>quote_len</th>\n",
       "      <th>pos_avg</th>\n",
       "      <th>neg_avg</th>\n",
       "      <th>obj_avg</th>\n",
       "      <th>pos_part_avg</th>\n",
       "      <th>neg_part_avg</th>\n",
       "      <th>obj_part_avg</th>\n",
       "      <th>ADJ_prop</th>\n",
       "      <th>ADP_prop</th>\n",
       "      <th>ADV_prop</th>\n",
       "      <th>CONJ_prop</th>\n",
       "      <th>DET_prop</th>\n",
       "      <th>INTJ_prop</th>\n",
       "      <th>NOUN_prop</th>\n",
       "      <th>PART_prop</th>\n",
       "      <th>PRON_prop</th>\n",
       "      <th>PROPN_prop</th>\n",
       "      <th>VERB_prop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>0.045647</td>\n",
       "      <td>0.024706</td>\n",
       "      <td>0.929647</td>\n",
       "      <td>0.069186</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>0.905260</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13</td>\n",
       "      <td>0.062271</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.915751</td>\n",
       "      <td>0.020833</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.153846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.153846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   quote_len   pos_avg   neg_avg   obj_avg  pos_part_avg  neg_part_avg  \\\n",
       "0         24  0.045647  0.024706  0.929647      0.069186      0.025553   \n",
       "1         13  0.062271  0.021978  0.915751      0.020833      0.000000   \n",
       "\n",
       "   obj_part_avg  ADJ_prop  ADP_prop  ADV_prop  CONJ_prop  DET_prop  INTJ_prop  \\\n",
       "0      0.905260  0.153846  0.115385  0.076923   0.076923  0.038462        0.0   \n",
       "1      0.979167  0.153846  0.153846  0.000000   0.000000  0.153846        0.0   \n",
       "\n",
       "   NOUN_prop  PART_prop  PRON_prop  PROPN_prop  VERB_prop  \n",
       "0   0.269231        0.0   0.076923         0.0   0.153846  \n",
       "1   0.384615        0.0   0.000000         0.0   0.153846  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xn = StandardScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 750 candidates, totalling 3750 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:    0.9s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:    3.7s\n",
      "[Parallel(n_jobs=1)]: Done 449 tasks       | elapsed:    8.3s\n",
      "[Parallel(n_jobs=1)]: Done 799 tasks       | elapsed:   14.9s\n",
      "[Parallel(n_jobs=1)]: Done 1249 tasks       | elapsed:   23.5s\n",
      "[Parallel(n_jobs=1)]: Done 1799 tasks       | elapsed:   33.7s\n",
      "[Parallel(n_jobs=1)]: Done 2449 tasks       | elapsed:   45.7s\n",
      "[Parallel(n_jobs=1)]: Done 3199 tasks       | elapsed:  1.0min\n",
      "[Parallel(n_jobs=1)]: Done 3750 out of 3750 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
       "       verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'penalty': ['elasticnet'], 'loss': ['log'], 'l1_ratio': array([ 0.01   ,  0.08071,  0.15143,  0.22214,  0.29286,  0.36357,\n",
       "        0.43429,  0.505  ,  0.57571,  0.64643,  0.71714,  0.78786,\n",
       "        0.85857,  0.92929,  1.     ]), 'alpha': array([  1.00000e-04,   1.32571e-04,   1.75751e-04...    2.44205e+01,   3.23746e+01,   4.29193e+01,   5.68987e+01,\n",
       "         7.54312e+01,   1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=1)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd_params = {\n",
    "    'loss':['log'],\n",
    "    'penalty':['elasticnet'],\n",
    "    'alpha':np.logspace(-4,2,50),\n",
    "    'l1_ratio':np.linspace(0.01, 1.0, 15)\n",
    "}\n",
    "\n",
    "sgd_gs = GridSearchCV(SGDClassifier(), sgd_params, cv=5, verbose=1)\n",
    "sgd_gs.fit(Xn, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.646723138654\n",
      "{'penalty': 'elasticnet', 'alpha': 0.0051794746792312128, 'loss': 'log', 'l1_ratio': 0.57571428571428573}\n"
     ]
    }
   ],
   "source": [
    "print sgd_gs.best_score_\n",
    "print sgd_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "quote_len 0.0822293966478\n",
      "pos_avg 0.173766610449\n",
      "neg_avg -0.308953504392\n",
      "obj_avg 0.0\n",
      "pos_part_avg 0.291492706393\n",
      "neg_part_avg 0.0\n",
      "obj_part_avg 0.0\n",
      "ADJ_prop 0.0728550950628\n",
      "ADP_prop 0.0\n",
      "ADV_prop -0.159857092263\n",
      "CONJ_prop 0.0844512198989\n",
      "DET_prop -0.0199989322871\n",
      "INTJ_prop 0.0\n",
      "NOUN_prop 0.125303028351\n",
      "PART_prop -0.0937812943019\n",
      "PRON_prop 0.0572366705904\n",
      "PROPN_prop 0.0528157059288\n",
      "VERB_prop -0.072128233792\n"
     ]
    }
   ],
   "source": [
    "for var, coef in zip(X.columns, sgd_gs.best_estimator_.coef_[0]):\n",
    "    print var, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
