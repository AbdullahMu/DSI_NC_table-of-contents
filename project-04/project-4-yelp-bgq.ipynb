{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 4\n",
    "\n",
    "###  Big Query, SQL, Classification\n",
    "\n",
    "---\n",
    "\n",
    "### The Data\n",
    "\n",
    "There are 5 individual tables that have the information, contained in a Google BigQuery database.  The setup info for BigQuery is located on our DSI wiki.  You will have to query with SQL, the dataset in order to complete this project.\n",
    "\n",
    "The tables, with cooresonding attributes that exist are:\n",
    "\n",
    "### businesses\n",
    "- business_id: unique business identifier\n",
    "- name: name of the business\n",
    "- review_count: number of reviews per business\n",
    "- city: city business resides in\n",
    "- stars: average rating\n",
    "- categories: categories the business falls into (can be one or multiple)\n",
    "- latitude\n",
    "- longitude\n",
    "- neighborhoods: neighborhoods business belongs to\n",
    "- variable: \"property\" of the business (a tag)\n",
    "- value: True/False for the property\n",
    "\n",
    "### reviews\n",
    "- user_id: unique user identifier\n",
    "- review_id: unique review identifier\n",
    "- votes.cool: how many thought the review was \"cool\"\n",
    "- business_id: unique business id the review is for\n",
    "- votes.funny: how many thought the review was funny\n",
    "- stars: rating given\n",
    "- date: date of review\n",
    "- votes.useful: how many thought the review was useful\n",
    "- ... 100 columns of counts of most common 2 word phrases that appear in reviews in this review\n",
    "\n",
    "### users\n",
    "- yelping_since: signup date\n",
    "- compliments.plain: # of compliments \"plain\"\n",
    "- review_count: # of reviews:\n",
    "- compliments.cute: total # of compliments \"cute\"\n",
    "- compliments.writer: # of compliments \"writer\"\n",
    "- compliments.note: # of compliments \"note\" (not sure what this is)\n",
    "- compliments.hot: # of compliments \"hot\" (?)\n",
    "- compliments.cool: # of compliments \"cool\"\n",
    "- compliments.profile: # of compliments \"profile\"\n",
    "- average_stars: average rating\n",
    "- compliments.more: # of compliments \"more\"\n",
    "- elite: years considered \"elite\"\n",
    "- name: user's name\n",
    "- user_id: unique user id\n",
    "- votes.cool: # of votes \"cool\"\n",
    "- compliments.list: # of compliments \"list\"\n",
    "- votes.funny: # of compliments \"funny\"\n",
    "- compliments.photos: # of compliments \"photos\"\n",
    "- compliments.funny: # of compliments \"funny\"\n",
    "- votes.useful: # of votes \"useful\"\n",
    "\n",
    "### checkins\n",
    "- business_id: unique business identifier\n",
    "- variable: day-time identifier of checkins (0-0 is Sunday 0:00 - 1:00am,  for example)\n",
    "- value: # of checkins at that time\n",
    "\n",
    "### tips\n",
    "- user_id: unique user identifier\n",
    "- business_id: unique business identifier\n",
    "- likes: likes that the tip has\n",
    "- date: date of tip\n",
    "- ... 100 columns of counts of most common 2 word phrases that appear in tips in this tip\n",
    "\n",
    "\n",
    "The reviews and tips datasets in particular have parsed \"NLP\" columns with counts of 2-word phrases in that review or tip (a \"tip\", it seems, is some kind of smaller review).\n",
    "\n",
    "The user dataset has a lot of columns of counts of different compliments and votes. We're not sure whether the compliments or votes are by the user or for the user.\n",
    "\n",
    "Full details about this dataset area located here:\n",
    "https://bigquery.cloud.google.com/dataset/bigquery-dsi-dave:yelp_arizona\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "If you look at the website, or the full data, you'll see I have removed pieces of the data and cut it down quite a bit. This is to simplify it for this project. Specifically, business are limited to be in these cities:\n",
    "\n",
    "- Phoenix\n",
    "- Surprise\n",
    "- Las Vegas\n",
    "- Waterloo\n",
    "\n",
    "Apparently there is a city called \"Surprise\" in Arizona. \n",
    "\n",
    "Businesses are also restricted to at least be in one of the following categories, because we thought the mix of them was funny:\n",
    "\n",
    "- Airports\n",
    "- Breakfast & Brunch\n",
    "- Bubble Tea\n",
    "- Burgers\n",
    "- Bars\n",
    "- Bakeries\n",
    "- Breweries\n",
    "- Cafes\n",
    "- Candy Stores\n",
    "- Comedy Clubs\n",
    "- Courthouses\n",
    "- Dance Clubs\n",
    "- Fast Food\n",
    "- Museums\n",
    "- Tattoo\n",
    "- Vape Shops\n",
    "- Yoga\n",
    "    \n",
    "---\n",
    "\n",
    "### Project requirements\n",
    "\n",
    "**You will be performing 4 different sections of analysis, like in the last project.**\n",
    "\n",
    "Remember that classification targets are categorical and regression targets are continuous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1. Load your dataset(s) / setup / configure GBQ connection\n",
    "\n",
    "---\n",
    "\n",
    "Information about this dataset is located here:\n",
    "\n",
    "\n",
    "**If you haven't done so, setup a project with the Google developer portal, following the directions here: [Getting Started with BigQuery](https://github.com/ga-students/DSI-SF-4/wiki/Getting-Started-with-BigQuery)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "project_id = \"your project id here\"\n",
    "\n",
    "sql = \"\"\"\n",
    "SELECT * FROM [bigquery-dsi-dave:yelp_arizona.reviews] \n",
    "LIMIT 2500\n",
    "\"\"\"\n",
    "\n",
    "df = pd.read_gbq(sql, project_id=project_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'user_id', u'review_id', u'votes_cool', u'business_id', u'votes_funny',\n",
       "       u'stars', u'date', u'votes_useful', u'minutes_10', u'minutes_15',\n",
       "       ...\n",
       "       u'service_great', u'staff_friendly', u'super_friendly', u'sweet_potato',\n",
       "       u'tasted_like', u'time_vegas', u'try_place', u've_seen', u've_tried',\n",
       "       u'wait_staff'],\n",
       "      dtype='object', length=108)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2. Constructing a \"profile\" for Las Vegas\n",
    "\n",
    "---\n",
    "\n",
    "Yelp is interested in building out what they are calling \"profiles\" for cities. They want you to start with just Las Vegas to see what a prototype of this would look like. Essentially, they want to know what makes Las Vegas distinct from the other four.\n",
    "\n",
    "Use the data you have to predict Las Vegas from the other variables you have. You should not be predicting the city from any kind of location data or other data perfectly associated with that city (or another city).\n",
    "\n",
    "You may use any classification algorithm you deem appropriate, or even multiple models. You should:\n",
    "\n",
    "1. Build at least one model predicting Las Vegas vs. the other cities.\n",
    "- Validate your model(s).\n",
    "- Interpret and visualize, in some way, the results.\n",
    "- Write up a \"profile\" for Las Vegas. This should be a writeup converting your findings from the model(s) into a human-readable description of the city.\n",
    "\n",
    "*Research location data to find the city targets.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 3. Different categories of ratings\n",
    "\n",
    "---\n",
    "\n",
    "Yelp is finally ready to admit that their rating system sucks. No one cares about the ratings, they just use the site to find out what's nearby. The ratings are simply too unreliable for people. \n",
    "\n",
    "Yelp hypothesizes that this is, in fact, because different people tend to give their ratings based on different things. They believe that perhaps some people always base their ratings on quality of food, others on service, and perhaps other categories as well. \n",
    "\n",
    "1. Do some users tend to talk about service more than others in reviews/tips? Divide up the tips/reviews into more \"service-focused\" ones and those less concerned with service.\n",
    "2. Create two new ratings for businesses: ratings from just the service-focused reviews and ratings from the non-service reviews.\n",
    "3. Construct a regression model for each of the two ratings. They should use the same predictor variables (of your choice). \n",
    "4. Validate the performance of the models.\n",
    "5. Do the models coefficients differ at all? What does this tell you about the hypothesis that there are in fact two different kinds of ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 4. Identifying \"elite\" users\n",
    "\n",
    "---\n",
    "\n",
    "Yelp, though having their own formula for determining whether a user is elite or not, is interested in delving deeper into what differentiates an elite user from a normal user at a broader level.\n",
    "\n",
    "Use a classification model to predict whether a user is elite or not. Note that users can be elite in some years and not in others.\n",
    "\n",
    "1. What things predict well whether a user is elite or not?\n",
    "- Validate the model.\n",
    "- If you were to remove the \"counts\" metrics for users (reviews, votes, compliments), what distinguishes an elite user, if anything? Validate the model and compare it to the one with the count variables.\n",
    "- Think of a way to visually represent your results in a compelling way.\n",
    "- Give a brief write-up of your findings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 5. Find something interesting on your own\n",
    "\n",
    "---\n",
    "\n",
    "You want to impress your superiors at Yelp by doing some investigation into the data on your own. You want to do classification, but you're not sure on what.\n",
    "\n",
    "1. Create a hypothesis or hypotheses about the data based on whatever you are interested in, as long as it is predicting a category of some kind (classification).\n",
    "2. Explore the data visually (ideally related to this hypothesis).\n",
    "3. Build one or more classification models to predict your target variable. **Your modeling should include gridsearching to find optimal model parameters.**\n",
    "4. Evaluate the performance of your model. Explain why your model may have chosen those specific parameters during the gridsearch process.\n",
    "5. Write up what the model tells you. Does it validate or invalidate your hypothesis? Write this up as if for a non-technical audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 6. ROC and Precision-recall\n",
    "\n",
    "---\n",
    "\n",
    "Some categories have fewer overall businesses than others. Choose two categories of businesses to predict, one that makes your proportion of target classes as even as possible, and another that has very few businesses and thus makes the target varible imbalanced.\n",
    "\n",
    "1. Create two classification models predicting these categories. Optimize the models and choose variables as you see fit.\n",
    "- Make confusion matrices for your models. Describe the confusion matrices and explain what they tell you about your models' performance.\n",
    "- Make ROC curves for both models. What do the ROC curves describe and what do they tell you about your model?\n",
    "- Make Precision-Recall curves for the models. What do they describe? How do they compare to the ROC curves?\n",
    "- Explain when Precision-Recall may be preferable to ROC. Is that the case in either of your models?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [dsi]",
   "language": "python",
   "name": "Python [dsi]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
